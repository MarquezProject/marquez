/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package marquez.spark;

import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.io.PrintWriter;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.junit.Test;

public class AppTest {

  static class Dump implements Runnable {
    private InputStream from;
    private OutputStream to;

    public Dump(InputStream from, OutputStream to) {
      this.from = from;
      this.to = to;

    }

    public void run() {
      try {
        from.transferTo(to);
      } catch (IOException e) {
        e.printStackTrace();
      }
    }
  }

  @Test
  public void testInspectPlan() throws IOException {
    SparkConf conf = new SparkConf()
        .setAppName("my-app")
        .setMaster("local[2]");
    try (JavaSparkContext sc = new JavaSparkContext(conf);) {

      PrintWriter w = new PrintWriter(new FileWriter("/tmp/test.csv"));
      w.println("1,2,3");
      w.println("4,5,6");
      w.close();
      File out = new File("/tmp/out.csv");
      if (out.exists() && out.isDirectory()) {
        for (File f : out.listFiles()) {
          f.delete();
        }
        out.delete();
      }

      JavaRDD<String> rdd = sc
          .textFile("file:///tmp/test.csv")
          .distinct();
      rdd.saveAsTextFile("file:///tmp/out.csv");
    }
  }

}
