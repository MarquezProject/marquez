"use strict";(self.webpackChunkmarquez_website_docs=self.webpackChunkmarquez_website_docs||[]).push([[1477],{30010:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"first-meetup","metadata":{"permalink":"/blog/first-meetup","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2023-08-14-first-meetup.mdx","source":"@site/blog/2023-08-14-first-meetup.mdx","title":"Join Us in October for Our First Meetup","description":"The first Marquez meetup will be held on 10/5/23 in San Francisco at Astronomer\'s HQ.","date":"2023-08-14T00:00:00.000Z","formattedDate":"August 14, 2023","tags":[{"label":"meetups","permalink":"/blog/tags/meetups"}],"readingTime":1.07,"hasTruncateMarker":true,"authors":[{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","image_url":"https://github.com/merobi-hub.png","imageURL":"https://github.com/merobi-hub.png"}],"frontMatter":{"slug":"first-meetup","description":"The first Marquez meetup will be held on 10/5/23 in San Francisco at Astronomer\'s HQ.","title":"Join Us in October for Our First Meetup","authors":{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","image_url":"https://github.com/merobi-hub.png","imageURL":"https://github.com/merobi-hub.png"},"tags":["meetups"]},"nextItem":{"title":"The February Marquez Community Meeting Focused on UI Upgrades and Recent Releases","permalink":"/blog/2-23-meeting"}},"content":"Join us on Thursday, October 5th, from 5:30-8:30 pm to learn about the present \\nand future of the Marquez project. \\n\\n\x3c!--truncate--\x3e\\n\\nYou will: \\n- meet other members of the community, \\n- learn about the project\u2019s goals and fundamental design, \\n- hear about the project\'s journey from WeWork to OpenLineage adoption to Astronomer,\\n- brainstorm about data lineage, \\n- participate in a discussion about the future of the project, &\\n- submit your first PR to the project. \\nIf that\'s not enough, there will also be stickers! Bring your appetite and your \\nideas and vision for Marquez!\\n\\nFood will be provided, and the meetup is open to all. Don\'t miss this opportunity \\nto influence the direction of the project! We hope to see you there. Please \\n[sign up](https://www.meetup.com/meetup-group-bnfqymxe/events/295444209/?utm_medium=referral&utm_campaign=share-btn_savedevents_share_modal&utm_source=link) to let us know you\'re coming.\\n\\n### Time, Place & Format\\n\\nDate: October 5, 2023  \\nFormat: In-person  \\nTime: 5:30-8:30 pm ET  \\nAddress: Astronomer, [8 California Street, 7th Floor, San Francisco, CA 94111](https://goo.gl/maps/7UxfePDNPkneyc8v5?coh=178571&entry=tt)\\n\\n#### Getting There\\nThe Astronomer SF office is in the Financial District at the corner of California\\nand Drumm Streets, catty-cornered from the Market/Drumm Street cable car stop.\\n\\n#### Getting In \\nAn Astronomer team member in the lobby will direct you to the Astronomer offices \\non the seventh floor.\\n\\n### Hope to see you there!"},{"id":"2-23-meeting","metadata":{"permalink":"/blog/2-23-meeting","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2023-02-27-2-23-meeting.mdx","source":"@site/blog/2023-02-27-2-23-meeting.mdx","title":"The February Marquez Community Meeting Focused on UI Upgrades and Recent Releases","description":"Did you miss the most recent community meeting? Get caught up here.","date":"2023-02-27T00:00:00.000Z","formattedDate":"February 27, 2023","tags":[{"label":"web","permalink":"/blog/tags/web"},{"label":"releases","permalink":"/blog/tags/releases"}],"readingTime":0.915,"hasTruncateMarker":true,"authors":[{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","imageURL":"https://github.com/merobi-hub.png","key":"Robinson"}],"frontMatter":{"slug":"2-23-meeting","description":"Did you miss the most recent community meeting? Get caught up here.","title":"The February Marquez Community Meeting Focused on UI Upgrades and Recent Releases","authors":["Robinson"],"tags":["web","releases"]},"prevItem":{"title":"Join Us in October for Our First Meetup","permalink":"/blog/first-meetup"},"nextItem":{"title":"Marquez 0.30.0 offers a big performance bump, with some assembly required","permalink":"/blog/version-30-upgrades"}},"content":"If you couldn\'t attend the monthly community meeting last week, here\'s a rundown of\\nwhat you missed.\\n\\n\x3c!--truncate--\x3e\\n\\n### February 2023 Marquez Community Meeting Highlights\\n\\n- Announcements: Willy Lulciuc was voted Technical Lead (congrats, Willy!), and the \\nLFAI&Data conducted its annual review of the project.\\n- Recent releases: we released Marquez 0.30.0 and 0.31.0. Read the \\n[migration plan](https://github.com/MarquezProject/marquez/blob/main/api/src/main/resources/marquez/db/migration/V57__readme.md) before upgrading to \\n0.30.0.\\n- UI improvements: as demo\'ed by Peter Hicks, Marquez now features critical path\\nhighlighting, search functionality and clickable links in column-lineage JSON snippets, a lineage\\nevents viewer, and a soft delete option for datasets and jobs.\\n- Open discussion: Benji asked if the soft-delete option was available elsewhere\\nin the UI (not yet, but aggregation of functions is planned), yours truly highlighted an exciting recently added \\n[issue](https://github.com/MarquezProject/marquez/issues/2428), and new member Bruno \\nCavestro asked about the project\'s philosophy, focus on big data tooling, and facets.\\n\\nFor more detailed information:\\n- Check out the [wiki](https://bit.ly/MarquezMeet) for meeting notes and the Zoom link.\\n- Browse the [YouTube channel](https://bit.ly/MarquezYouTube) for recordings of all meetings.\\n\\nHope to see you at the next meeting on March 23rd!"},{"id":"version-30-upgrades","metadata":{"permalink":"/blog/version-30-upgrades","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2023-02-03-version-30-upgrades.mdx","source":"@site/blog/2023-02-03-version-30-upgrades.mdx","title":"Marquez 0.30.0 offers a big performance bump, with some assembly required","description":"How to ensure a smooth transition to the latest version of Marquez.","date":"2023-02-03T00:00:00.000Z","formattedDate":"February 3, 2023","tags":[{"label":"releases","permalink":"/blog/tags/releases"},{"label":"web","permalink":"/blog/tags/web"}],"readingTime":2.5,"hasTruncateMarker":true,"authors":[{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","image_url":"https://github.com/merobi-hub.png","imageURL":"https://github.com/merobi-hub.png"}],"frontMatter":{"slug":"version-30-upgrades","description":"How to ensure a smooth transition to the latest version of Marquez.","title":"Marquez 0.30.0 offers a big performance bump, with some assembly required","authors":{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","image_url":"https://github.com/merobi-hub.png","imageURL":"https://github.com/merobi-hub.png"},"tags":["releases","web"]},"prevItem":{"title":"The February Marquez Community Meeting Focused on UI Upgrades and Recent Releases","permalink":"/blog/2-23-meeting"},"nextItem":{"title":"Trying Out the New Column Lineage Feature","permalink":"/blog/column-lineage-demo"}},"content":"This is a guide to making a smooth transition to the latest version of Marquez.\\n\\n\x3c!--truncate--\x3e\\n\\n## Marquez 0.30.0\\n\\n[Marquez 0.30.0](https://github.com/MarquezProject/marquez/releases/tag/0.30.0), \\nwhich we released on 2023-01-31, contains some exciting new features, including \\n[column-level lineage](https://github.com/MarquezProject/marquez/pull/2293) and \\na [soft delete option](https://github.com/MarquezProject/marquez/pull/2343) in \\nthe UI.\\n\\nAlong with these long-awaited UI upgrades come some significant performance \\nimprovements to the API. In prior versions of Marquez, accessing OpenLineage \\nfacets required direct queries against the OpenLineage events table, which could \\nbe quite costly depending on the size of this table. Some users have events \\ntables with more than 100K rows -- millions of rows, in fact. To address this \\nperformance issue, Marquez 0.30.0 has new tables for dataset, job and run facets.\\n\\nSo far, so simple, right? Protecting against data loss and ensuring a smooth \\nexperience for users was not so simple, in fact. We needed a way to migrate the \\ndata while not only avoiding loss but also keeping downtime to a minimum. The \\nsolution that [Willy](https://github.com/wslulciuc) and \\n[Pawel](https://github.com/pawel-big-lebowski) found (with input from \\n[Mike Collado](https://github.com/collado-mike)) was to keep the data in the \\nevents table until the migration process is complete and to create views on top \\nof the table for accessing the facets. After migration is complete, the views \\nare replaced to point to the new tables. Using views provides safeguards and \\nminimizes downtime during the migration. \\n\\n## Migration Procedure\\n\\nAs the \\n[migration plan](https://github.com/MarquezProject/marquez/blob/main/api/src/main/resources/marquez/db/migration/V57__readme.md) \\nsays, users whose `lineage_events` tables have up to 100K rows can set it and \\nforget it -- no extra work is required beyond upgrading and restarting \\nMarquez, but be prepared for a brief downtime while a standard Flyway migration \\nfills the newly created tables automatically.\\n\\nFor heavy users whose `lineage_events` tables have more than 100K rows, a \\ndifferent process will be used. Instead of a standard migration, the process will \\nhappen asynchronously so that the user can start the API and consume new \\nOpenLineage events as usual. Note that some API calls might return results\\nslowly during the migration, especially if the output is based on facets.\\n\\nTo perform a migration, these users must run a new `db-migrate` command:\\n\\n```\\njava -jar api/build/libs/marquez-api-0.30.0.jar db-migrate --version v57 ./marquez.yml\\n```\\n\\nAvailable command arguments, `version` (required) and `chunkSize` (optional), \\nallow the user to specify the migration version to apply and the number of \\nlineage events to process (the default being 10,000). The command will process \\nthe data not in its entirety but in chunks, storing a state with information \\nabout the chunks being processed. Consequently,\\n\\n- it can be stopped any time\\n- it will continue automatically and process the remaining chunks. \\n\\nA sample command specifying version 57 and 50,000 events:\\n\\n```\\njava -jar api/build/libs/marquez-api-0.30.0.jar db-migrate --version v57 --chunkSize 50000 ./marquez.yml\\n```\\n\\n## More Information\\n\\nFor more details about what, if anything, you will need to do to ensure a smooth \\ntransition to Marquez 0.30.0, check out the helpful\\n[migration plan](https://github.com/MarquezProject/marquez/blob/main/api/src/main/resources/marquez/db/migration/V57__readme.md) \\nput together by [Willy](https://github.com/wslulciuc) and \\n[Pawel](https://github.com/pawel-big-lebowski). \\n\\nFor more information about the improvements and additions in Marquez 0.30.0, check \\nout [the release on GitHub](https://github.com/MarquezProject/marquez/releases/tag/0.30.0)."},{"id":"column-lineage-demo","metadata":{"permalink":"/blog/column-lineage-demo","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2022-10-25-column-lineage-demo.mdx","source":"@site/blog/2022-10-25-column-lineage-demo.mdx","title":"Trying Out the New Column Lineage Feature","description":"How to get started with the new column lineage feature in Marquez.","date":"2022-10-25T00:00:00.000Z","formattedDate":"October 25, 2022","tags":[{"label":"column lineage","permalink":"/blog/tags/column-lineage"},{"label":"Spark","permalink":"/blog/tags/spark"},{"label":"releases","permalink":"/blog/tags/releases"},{"label":"demos","permalink":"/blog/tags/demos"}],"readingTime":4.41,"hasTruncateMarker":true,"authors":[{"name":"Pawel Leszczynski","title":"Marquez Committer","url":"https://github.com/pawel-big-lebowski","imageURL":"https://github.com/pawel-big-lebowski.png","key":"Leszczynski"},{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","imageURL":"https://github.com/merobi-hub.png","key":"Robinson"}],"frontMatter":{"slug":"column-lineage-demo","description":"How to get started with the new column lineage feature in Marquez.","title":"Trying Out the New Column Lineage Feature","authors":["Leszczynski","Robinson"],"tags":["column lineage","Spark","releases","demos"]},"prevItem":{"title":"Marquez 0.30.0 offers a big performance bump, with some assembly required","permalink":"/blog/version-30-upgrades"},"nextItem":{"title":"Using the New Soft-delete Feature","permalink":"/blog/soft-delete"}},"content":"Read on to learn how to get started with the new column lineage feature in Marquez.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nWe are excited to announce the addition of column-level lineage to Marquez with the release of 0.27.0. One of our most frequently requested new features, column-level lineage makes dataset column inputs and outputs available via the Marquez API. We\u2019re pleased to be able to share this new feature now, and we welcome contributors to this important development in the project.\\n\\nOur plans for the feature include support beyond the Spark integration as well as UI support for column lineage.  \\n\\n## What is column lineage and why is it important?\\n\\nSimply put, column lineage is lineage data about columns. This means that in addition to emitting dataset inputs and outputs, the OpenLineage-Spark integration now emits column inputs and outputs. Thanks to this metadata, users can glean information about the input columns that were used to produce the columns of a dataset.\\n\\nA major benefit of column lineage is the finer granularity of the data that one gets thanks to the deeper level of insight into a pipeline. For example, column lineage lets you track the usage of sensitive data, such customers\u2019 personal information, by members of your organization. This capability is essential to meeting some requirements of regulatory bodies such as the [GDPR](https://gdpr-info.eu/), [HIPAA](https://www.hhs.gov/hipaa/index.html), [CCPA](https://oag.ca.gov/privacy/ccpa), [BCBS](https://www.bis.org/bcbs/) and [PCI](https://www.pcisecuritystandards.org/), who have instituted requirements for data accuracy and integrity that compel companies and organizations to monitor their datasets and pipelines more closely than in the past. \\n\\n## How It Works\\n\\nThe spec uses a new facet, [`ColumnLineageDatasetFacet`](https://github.com/OpenLineage/OpenLineage/blob/main/spec/facets/ColumnLineageDatasetFacet.json), to store column lineage. For each column of an output dataset, the facet relays a list of columns from the input datasets that were used to produce the column.\\n\\nHere\u2019s the new facet in the OpenLineage spec:\\n\\n```\\n{\\n  \\"$schema\\": \\"https://json-schema.org/draft/2020-12/schema\\",\\n  \\"$id\\": \\"https://openlineage.io/spec/facets/1-0-1/ColumnLineageDatasetFacet.json\\",\\n  \\"$defs\\": {\\n    \\"ColumnLineageDatasetFacet\\": {\\n      \\"allOf\\": [{\\n        \\"$ref\\": \\"https://openlineage.io/spec/1-0-2/OpenLineage.json#/$defs/DatasetFacet\\"\\n      }, {\\n        \\"type\\": \\"object\\",\\n        \\"properties\\": {\\n          \\"fields\\": {\\n            \\"description\\": \\"Column level lineage that maps output fields into input fields used to evaluate them.\\",\\n            \\"type\\": \\"object\\",\\n            \\"additionalProperties\\": {\\n              \\"type\\": \\"object\\",\\n              \\"properties\\": {\\n                \\"inputFields\\": {\\n                  \\"type\\": \\"array\\",\\n                  \\"items\\": {\\n                    \\"type\\": \\"object\\",\\n                    \\"properties\\": {\\n                      \\"namespace\\": {\\n                        \\"type\\": \\"string\\",\\n                        \\"description\\": \\"The input dataset namespace\\"\\n                      },\\n                      \\"name\\": {\\n                        \\"type\\": \\"string\\",\\n                        \\"description\\": \\"The input dataset name\\"\\n                      },\\n                      \\"field\\": {\\n                        \\"type\\": \\"string\\",\\n                        \\"description\\": \\"The input field\\"\\n                      }\\n                    },\\n                    \\"additionalProperties\\": true,\\n                    \\"required\\": [\\n                      \\"namespace\\", \\"name\\", \\"field\\"\\n                    ]\\n                  }\\n                },\\n                \\"transformationDescription\\": {\\n                   \\"type\\": \\"string\\",\\n                   \\"description\\": \\"a string representation of the transformation applied\\"\\n                },\\n                \\"transformationType\\": {\\n                   \\"type\\": \\"string\\",\\n                   \\"description\\": \\"IDENTITY|MASKED reflects a clearly defined behavior. IDENTITY: exact same as input; MASKED: no original data available (like a hash of PII for example)\\"\\n                }\\n              },\\n              \\"additionalProperties\\": true,\\n              \\"required\\": [\\"inputFields\\"]\\n            }      \\n          }    \\n        },\\n        \\"additionalProperties\\": true,\\n        \\"required\\": [\\n          \\"fields\\"\\n        ]\\n      }],\\n      \\"type\\": \\"object\\"\\n    }\\n  },\\n  \\"type\\": \\"object\\",\\n  \\"properties\\": {\\n    \\"columnLineage\\": {\\n      \\"$ref\\": \\"#/$defs/ColumnLineageDatasetFacet\\"\\n    }\\n  }\\n}\\n```\\n\\nAs you can see above, two extra fields offer the ability to emit additional information: `transformationDescription` and `transformationType`. The `transformationDescription` field emits a string describing the transformations of input columns that have produced an output column. The `transformationType` field, a string field containing either `IDENTITY` or `MASKED`, indicates whether the column data is exactly the same as the input data or if no original data is available (as in the case of encrypted data).\\n\\nSupport for column lineage is currently limited to the Spark integration, which now detects column lineage out of the box. Also, the Marquez API now contains methods to retrieve column lineage in graph form.\\n\\nThe new API endpoint (at `api/src/main/java/marquez/api/ColumnLineageResource.java`):\\n\\n```\\npublic class ColumnLineageResource extends BaseResource {\\n\\n    private static final String DEFAULT_DEPTH = \\"20\\";\\n\\n    public ColumnLineageResource(@NonNull final ServiceFactory serviceFactory) {\\n    super(serviceFactory);\\n    }\\n\\n    @Timed\\n    @ResponseMetered\\n    @ExceptionMetered\\n    @GET\\n    @Produces(APPLICATION_JSON)\\n    public Response getLineage(\\n        @QueryParam(\\"nodeId\\") @NotNull NodeId nodeId,\\n        @QueryParam(\\"depth\\") @DefaultValue(DEFAULT_DEPTH) int depth,\\n        @QueryParam(\\"withDownstream\\") @DefaultValue(\\"false\\") boolean withDownstream)\\n        throws ExecutionException, InterruptedException {\\n    return Response.ok(columnLineageService.lineage(nodeId, depth, withDownstream, Instant.now()))\\n        .build();\\n    }\\n}\\n```\\n\\n## Getting Started\\n\\n[A new workshop](https://github.com/OpenLineage/workshops/tree/main/spark) in the OpenLineage/workshops repository provides an easy way to try out the new feature in a Jupyter Notebook using Git, Docker, and Marquez. \\n\\nWhat you\u2019ll need:\\n- Docker 17.05+\\n- Docker Compose 1.29.1+\\n- Git (preinstalled on most versions of MacOS; verify with git version)\\n- 4 GB of available memory (the minimum for Docker \u2014 more is strongly recommended)\\n\\nWhat you\u2019ll learn:\\n- how to get started with Marquez\\n- how to start a Spark context with OpenLineage pointed at Marquez\\n- how to run a sample Spark job resulting in a lineage graph\\n- how to query the Marquez API for a dataset resource with column lineage included.\\n\\n## Next steps\\n\\nSupport for column lineage is currently limited to the Spark integration, but we intend to expand the feature. Our plans include:\\n- adding support for column lineage in the UI\\n- enabling the SQL Parser to extract column lineage from SQL queries\\n- adding the ability to detect sensitive data across all datasets based on column lineage and information about raw data in the ecosystem.\\n\\n## How to contribute\\n\\nWe would love to help others develop the column-level lineage features they need, and we welcome contributions to this ongoing effort at implementing column-level lineage in Marquez! If you have experience doing frontend development, the UI work might be a good place to start. \\n\\nDoes this sound fun? Check out our [new contributor guide](https://github.com/MarquezProject/marquez/blob/main/CONTRIBUTING.md) to get started."},{"id":"soft-delete","metadata":{"permalink":"/blog/soft-delete","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2022-10-25-soft-delete/index.mdx","source":"@site/blog/2022-10-25-soft-delete/index.mdx","title":"Using the New Soft-delete Feature","description":"How to use the new soft-delete feature to clean up your lineage graphs","date":"2022-10-25T00:00:00.000Z","formattedDate":"October 25, 2022","tags":[{"label":"API","permalink":"/blog/tags/api"},{"label":"web","permalink":"/blog/tags/web"},{"label":"features","permalink":"/blog/tags/features"}],"readingTime":5.195,"hasTruncateMarker":true,"authors":[{"name":"Maciej Obuchowski","title":"Marquez Committer","url":"https://github.com/mobuchowski","imageURL":"https://github.com/mobuchowski.png","key":"Obuchowski"},{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","imageURL":"https://github.com/merobi-hub.png","key":"Robinson"}],"frontMatter":{"slug":"soft-delete","description":"How to use the new soft-delete feature to clean up your lineage graphs","title":"Using the New Soft-delete Feature","authors":["Obuchowski","Robinson"],"tags":["API","web","features"]},"prevItem":{"title":"Trying Out the New Column Lineage Feature","permalink":"/blog/column-lineage-demo"},"nextItem":{"title":"Exploring the Marquez Lineage API","permalink":"/blog/using-marquez-api"}},"content":"Read on to learn how to use the new soft-delete feature to clean up your lineage graphs.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nAn exciting new feature is coming to the Marquez UI: the ability to \u201csoft delete\u201d datasets and jobs. Once work on the feature is finished, users will be able to hide inactive datasets and jobs from the UI, allowing for the easy removal of unused or stale metadata. At this point, most of the necessary backend development is complete. \\n\\n## Motivations and Goals\\nThe idea for this feature came out of a need to keep deleted or renamed datasets and jobs from cluttering the lineage view in Marquez. In Issue [#1736](https://github.com/MarquezProject/marquez/issues/1736), project co-creator [Julien Le Dem](https://github.com/julienledem) suggested a change to the internal Marquez model to create a \u201cnew\u201d version of such a dataset or job \u2013 a deleted version \u2013 that would not show up in the current lineage view produced by `GET /api/v1/lineage`.  \\n\\n## How It Works\\n\\nAs noted in pull request [#2032](https://github.com/MarquezProject/marquez/pull/2032), the feature works by adding a new flag, `is_hidden`, to the datasets and jobs a user wishes to hide. Then, it changes the jobs_view and adds a datasets_view that hides any rows where the is_hidden flag is set to true. Currently, the feature operates via API endpoint.\\n\\nConveniently, the soft-delete condition is reversed whenever the job or dataset is updated because the new version automatically reverts the flag. This allows Marquez users to preserve dataset and job histories regardless of deletion status.\\n\\nThe code to create a dataset migration view where the flag is used as a condition (`api/src/main/resources/marquez/db/migration/R__3_Datasets_view.sql`):\\n\\n```\\nCREATE OR REPLACE VIEW datasets_view\\nAS\\nSELECT uuid,\\n    type,\\n    created_at,\\n    updated_at,\\n    namespace_uuid,\\n    source_uuid,\\n    name,\\n    physical_name,\\n    description,\\n    current_version_uuid,\\n    last_modified_at,\\n    namespace_name,\\n    source_name,\\n    is_deleted\\nFROM datasets\\nWHERE is_hidden IS FALSE;\\n```\\n\\nThe new API endpoint in DatasetResource.java (`api/src/main/java/marquez/api/DatasetResource.java`):\\n\\n```\\n@Timed\\n@ResponseMetered\\n@ExceptionMetered\\n@DELETE\\n@Path(\\"{dataset}\\")\\n@Produces(APPLICATION_JSON)\\npublic Response delete(\\n    @PathParam(\\"namespace\\") NamespaceName namespaceName,\\n    @PathParam(\\"dataset\\") DatasetName datasetName) {\\nthrowIfNotExists(namespaceName);\\n\\nDataset dataset =\\n    datasetService\\n        .findDatasetByName(namespaceName.getValue(), datasetName.getValue())\\n        .orElseThrow(() -> new DatasetNotFoundException(datasetName));\\n\\ndatasetService\\n    .delete(namespaceName.getValue(), datasetName.getValue())\\n    .orElseThrow(() -> new DatasetNotFoundException(datasetName));\\nreturn Response.ok(dataset).build();\\n}\\n```\\n\\n## Querying and Viewing Datasets\\n\\nLet\u2019s try out the soft-delete feature on the `public.top_delivery_times` dataset in the `food_delivery` namespace that comes with Marquez out of the box. For more information about installing Marquez and using `--seed` for sample metadata when running Marquez, see the project [quickstart](https://marquezproject.ai/quickstart).\\n\\nFirst, verify that the dataset exists using the UI and the API.\\n\\nTo check via the API, run this command on the command line:\\n\\n```\\ncurl http://localhost:5000/api/v1/namespaces/food_delivery/datasets | jq\\n```\\n\\nThis command returns all the datasets in the `food_delivery` namespace. `top_delivery_times` should be at or near the end of the output.\\n\\nAlternatively, you could also query the database for this specific database with this command: \\n\\n```\\ncurl http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.top_delivery_times | jq)\\n```\\n\\nThe output should look something like this:\\n\\n```\\n{\\n      \\"id\\": {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.top_delivery_times\\"\\n      },\\n      \\"type\\": \\"DB_TABLE\\",\\n      \\"name\\": \\"public.top_delivery_times\\",\\n      \\"physicalName\\": \\"public.top_delivery_times\\",\\n      \\"createdAt\\": \\"2020-02-22T22:42:42Z\\",\\n      \\"updatedAt\\": \\"2020-02-22T22:42:42Z\\",\\n      \\"namespace\\": \\"food_delivery\\",\\n      \\"sourceName\\": \\"default\\",\\n      \\"fields\\": [\\n        {\\n          \\"name\\": \\"order_id\\",\\n          \\"type\\": \\"INTEGER\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The ID of the order.\\"\\n        },\\n        {\\n          \\"name\\": \\"order_placed_on\\",\\n          \\"type\\": \\"TIMESTAMP\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was placed.\\"\\n        },\\n        {\\n          \\"name\\": \\"order_dispatched_on\\",\\n          \\"type\\": \\"TIMESTAMP\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was dispatched.\\"\\n        },\\n        {\\n          \\"name\\": \\"order_delivered_on\\",\\n          \\"type\\": \\"TIMESTAMP\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was delivered.\\"\\n        },\\n        {\\n          \\"name\\": \\"order_delivered_time\\",\\n          \\"type\\": \\"TIMESTAMP\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"An ISO-8601 timestamp representing the total time of delivery.\\"\\n        },\\n        {\\n          \\"name\\": \\"customer_email\\",\\n          \\"type\\": \\"VARCHAR\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The email address of the customer.\\"\\n        },\\n        {\\n          \\"name\\": \\"restaurant_id\\",\\n          \\"type\\": \\"INTEGER\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The ID of the restaurant related to the order.\\"\\n        },\\n        {\\n          \\"name\\": \\"driver_id\\",\\n          \\"type\\": \\"INTEGER\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The ID of the driver related to the order.\\"\\n        }\\n      ],\\n      \\"tags\\": [],\\n      \\"lastModifiedAt\\": null,\\n      \\"lastLifecycleState\\": \\"\\",\\n      \\"description\\": null,\\n      \\"currentVersion\\": \\"7daad6c6-bbdb-4cf5-bee6-9c42c443732e\\",\\n      \\"columnLineage\\": null,\\n      \\"facets\\": {\\n        \\"schema\\": {\\n          \\"fields\\": [\\n            {\\n              \\"name\\": \\"order_id\\",\\n              \\"type\\": \\"INTEGER\\",\\n              \\"description\\": \\"The ID of the order.\\"\\n            },\\n            {\\n              \\"name\\": \\"order_placed_on\\",\\n              \\"type\\": \\"TIMESTAMP\\",\\n              \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was placed.\\"\\n            },\\n            {\\n              \\"name\\": \\"order_dispatched_on\\",\\n              \\"type\\": \\"TIMESTAMP\\",\\n              \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was dispatched.\\"\\n            },\\n            {\\n              \\"name\\": \\"order_delivered_on\\",\\n              \\"type\\": \\"TIMESTAMP\\",\\n              \\"description\\": \\"An ISO-8601 timestamp representing the date/time the order was delivered.\\"\\n            },\\n            {\\n              \\"name\\": \\"order_delivered_time\\",\\n              \\"type\\": \\"TIMESTAMP\\",\\n              \\"description\\": \\"An ISO-8601 timestamp representing the total time of delivery.\\"\\n            },\\n            {\\n              \\"name\\": \\"customer_email\\",\\n              \\"type\\": \\"VARCHAR\\",\\n              \\"description\\": \\"The email address of the customer.\\"\\n            },\\n            {\\n              \\"name\\": \\"restaurant_id\\",\\n              \\"type\\": \\"INTEGER\\",\\n              \\"description\\": \\"The ID of the restaurant related to the order.\\"\\n            },\\n            {\\n              \\"name\\": \\"driver_id\\",\\n              \\"type\\": \\"INTEGER\\",\\n              \\"description\\": \\"The ID of the driver related to the order.\\"\\n            }\\n          ],\\n          \\"_producer\\": \\"https://github.com/MarquezProject/marquez/blob/main/docker/metadata.json\\",\\n          \\"_schemaURL\\": \\"https://openlineage.io/spec/facets/1-0-0/SchemaDatasetFacet.json\\"\\n        }\\n      },\\n      \\"deleted\\": false\\n    }\\n  ]\\n```\\n\\nIn the UI, you can see the dataset in the `delivery_times_7_days` job:\\n\\n![Marquez UI lineage map](./dataset_verify.png)\\n\\n## Deleting Datasets\\n\\nTo delete this dataset, query the datasets endpoint with a DELETE API request:\\n\\n```\\ncurl -X DELETE http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.top_delivery_times | jq\\n```\\n\\nIt will output the dataset. Subsequent requests for the dataset will return 404s:\\n\\n```\\n{\\n  \\"code\\": 404,\\n  \\"message\\": \\"Dataset \'top_delivery_times\' not found.\\"\\n}\\n```\\n\\nThe UI will be updated accordingly. Note that the dataset is nowhere to be found in the `DATASETS` view or lineage map:\\n\\n![Marquez Datasets view](./datasets_delete_view.png)\\n\\n![Marquez Map view](./map_delete_view.png)\\n\\n## What\u2019s Next\\n\\nA new endpoint to make namespaces deletable is in progress ([Issue #2095](https://github.com/MarquezProject/marquez/issues/2095) & [PR #2172](https://github.com/MarquezProject/marquez/pull/2172)). The main goal of this addition is to automate the deletion of a large number of datasets and jobs where doing so individually would be a nuisance.\\n\\nThe frontend work is in the design stage. Some questions remain: How should the UI be modified to permit the selection of jobs and datasets for deletion? Should there be a new clickable element in every dataset and job in the graph? Should datasets and jobs be deletable within search results?\\n\\nWhoever takes on this task will have a shaping role in the discussion and ultimate form of this key addition.\\n\\n## Getting Started\\n\\nContributions to this ongoing effort at implementing a soft delete option Marquez are welcome. If you are interested in contributing, opening an [issue](https://github.com/MarquezProject/marquez/issues) is a good way to get started. \\n\\nCheck out our [new contributor guide](https://github.com/OpenLineage/OpenLineage/blob/main/CONTRIBUTING.md) to learn more about how to contribute to the project."},{"id":"using-marquez-api","metadata":{"permalink":"/blog/using-marquez-api","editUrl":"https://github.com/MarquezProject/marquez/tree/docs/v2/docs-v2/blog/2021-07-14-using-marquez-api/index.mdx","source":"@site/blog/2021-07-14-using-marquez-api/index.mdx","title":"Exploring the Marquez Lineage API","description":"How to use the API behind Marquez to explore datasets, jobs, and lineage","date":"2021-07-14T00:00:00.000Z","formattedDate":"July 14, 2021","tags":[{"label":"API","permalink":"/blog/tags/api"},{"label":"tutorials","permalink":"/blog/tags/tutorials"}],"readingTime":9.885,"hasTruncateMarker":true,"authors":[{"name":"Michael Robinson","title":"Marquez Community Manager","url":"https://github.com/merobi-hub","imageURL":"https://github.com/merobi-hub.png","key":"Robinson"}],"frontMatter":{"slug":"using-marquez-api","description":"How to use the API behind Marquez to explore datasets, jobs, and lineage","title":"Exploring the Marquez Lineage API","authors":["Robinson"],"tags":["API","tutorials"]},"prevItem":{"title":"Using the New Soft-delete Feature","permalink":"/blog/soft-delete"}},"content":"Read on to learn how to use the API behind Marquez to explore datasets, jobs, and lineage.\\n\\n\x3c!--truncate--\x3e\\n\\n## Background\\n\\nIf you\u2019re a Marquez user, then you might already know that the project is an open source metadata service for the collection, aggregation, and visualization of a data ecosystem\u2019s metadata. Based on the OpenLineage standard, it solves a hard problem: representing data pipeline lineage holistically and agnostically \u2013 or, more precisely, as holistically and agnostically as possible (lineage being above all else a pursuit).\\n\\nBut did you know that Marquez is also a metadata *server* that offers an OpenLineage-compatible endpoint for real-time metadata collection?\\n\\nThe key to the Marquez metadata server is the Marquez Lineage API, a REST API that offers users the ability to retrieve, modify, and add to the metadata about their pipelines in the Marquez database. In response to queries, the API emits JSON via HTTP.\\n\\n## Marquez API Functionality\\n\\n| *Namespace* | *Source* | *Dataset* | *Job* | *Lineage* | *Tags* | *Search* |\\n| --- | --- | --- | --- | --- | --- | --- |\\n| Retrieve a namespace | Retrieve a source | Retrieve a dataset | Retrieve a job | Record a single lineage event | Create a tag | Query all datasets and jobs |\\n| List all namespaces | List all sources | Retrieve a dataset version | List all jobs | Get a lineage graph | List all tags | |\\n| Create a namespace | | List all dataset versions | List all job versions | | | \\n| | | List all datasets | Retrieve a run | | | |\\n| | | Tag a dataset | | | | |\\n| | | Tag a field | | | | |\\n\\n## How to Use \\n\\n### Prerequisites\\n\\n- Docker 17.05+\\n- Docker Compose 1.29.1+\\n- Git (preinstalled on most versions of MacOS; verify with `git version`)\\n- 4 GB of available memory (the minimum for Docker \u2014 more is strongly recommended)\\n\\n### Install and Run Marquez \\n\\n1. Clone the Marquez Github [repository](https://github.com/MarquezProject/marquez): `git clone https://github.com/MarquezProject/marquez.git`\\n2. Start Docker\\n3. Run Marquez with seed data: `cd marquez && ./docker/up.sh --seed`\\n\\n### Explore Marquez \\n\\nPoint your browser to `http://localhost:3000`.\\n\\nAs you explore the UI, you\u2019ll notice a namespace (`ns`) dropdown on the top and job and dataset icons on the left. Everything viewable here is also queryable via the API.\\n\\n![Marquez UI](./marquez_ui.png)\\n\\n### Query the API\\n\\n#### View all Namespaces\\n\\nIn the OpenLineage spec, the namespace is at the top of the naming hierarchy. Practically speaking, namespaces are global contexts for jobs and datasets. In the case of a job, the namespace is related to the scheduler. In the case of a dataset, the namespace is the unique name of the dataset\u2019s datasource. \\n\\nTo view all the currently available namespaces (prettified) in the terminal, you could use: `curl http://localhost:5000/api/v1/namespaces | jq`.\\n\\nIf you started Marquez with seed data, you will see `food_delivery` in the output along with key data points about the namespace.\\n\\n#### Namespaces Query Output\\n\\n```\\n{\\n  \\"namespaces\\": [\\n    {\\n      \\"name\\": \\"default\\",\\n      \\"createdAt\\": \\"2022-07-12T16:22:11.080346Z\\",\\n      \\"updatedAt\\": \\"2022-07-12T16:22:11.080346Z\\",\\n      \\"ownerName\\": \\"anonymous\\",\\n      \\"description\\": \\"The default global namespace for dataset, job, and run metadata not belonging to a user-specified namespace.\\"\\n    },\\n    {\\n      \\"name\\": \\"food_delivery\\",\\n      \\"createdAt\\": \\"2022-07-12T16:22:12.518454Z\\",\\n      \\"updatedAt\\": \\"2022-07-12T16:22:23.724885Z\\",\\n      \\"ownerName\\": \\"owner@food.com\\",\\n      \\"description\\": \\"Food delivery example!\\"\\n    }\\n  ]\\n}\\n```\\nEvery other API call has to include a namespace, so it\u2019s important to know which namespace(s) you care about.\\n\\n#### Specify a Known Namespace \\n\\nLet\u2019s say you wanted more streamlined output and you already knew about the `food_delivery` namespace. Queries about known namespaces are also supported: `http://localhost:5000/api/v1/namespaces/{namespace}`.\\n\\nFor data about the `food_delivery` namespace, you could use: `curl http://localhost:5000/api/v1/namespaces/food_delivery | jq`.\\n\\nIn this case you\u2019ll see the name, time of creation, time of last update, owner, and description of only the namespace you provided.\\n\\n#### Namespace Output \\n```\\n{\\n  \\"name\\": \\"food_delivery\\",\\n  \\"createdAt\\": \\"2022-07-12T16:22:12.518454Z\\",\\n  \\"updatedAt\\": \\"2022-07-12T16:22:23.724885Z\\",\\n  \\"ownerName\\": \\"owner@food.com\\",\\n  \\"description\\": \\"Food delivery example!\\"\\n}\\n```\\n\\n#### View Key Data about a Dataset \\n\\nKnowing the available namespaces allows you to query the API for information about all the datasets in a namespace.\\n\\nFor example, to see all the datasets in the `food_delivery` namespace, you would use the following format: `http://localhost:5000/api/v1/namespaces/{namespace}/datasets`.\\n\\nTo view all the datasets in `food_delivery` you could use: `curl http://localhost:5000/api/v1/namespaces/food_delivery/datasets | jq`.\\n\\n#### Datasets Query Output (excerpt)\\n```\\n{\\n  \\"totalCount\\": 13,\\n  \\"datasets\\": [\\n    {\\n      \\"id\\": {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.categories\\"\\n      },\\n      \\"type\\": \\"DB_TABLE\\",\\n      \\"name\\": \\"public.categories\\",\\n      \\"physicalName\\": \\"public.categories\\",\\n      \\"createdAt\\": \\"2022-07-12T16:22:12.792434Z\\",\\n      \\"updatedAt\\": \\"2022-07-12T16:24:33.355699Z\\",\\n      \\"namespace\\": \\"food_delivery\\",\\n      \\"sourceName\\": \\"analytics_db\\",\\n      \\"fields\\": [\\n        {\\n          \\"name\\": \\"id\\",\\n          \\"type\\": \\"INTEGER\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The unique ID of the category.\\"\\n        },\\n        {\\n          \\"name\\": \\"name\\",\\n          \\"type\\": \\"VARCHAR\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The name of the category.\\"\\n        },\\n        {\\n          \\"name\\": \\"menu_id\\",\\n          \\"type\\": \\"INTEGER\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The ID of the menu related to the category.\\"\\n        },\\n        {\\n          \\"name\\": \\"description\\",\\n          \\"type\\": \\"TEXT\\",\\n          \\"tags\\": [],\\n          \\"description\\": \\"The description of the category.\\"\\n        }\\n      ],\\n      \\"tags\\": [],\\n      \\"lastModifiedAt\\": \\"2022-07-12T16:24:33.355699Z\\",\\n      \\"lastLifecycleState\\": null,\\n      \\"description\\": \\"A table for categories.\\",\\n      \\"currentVersion\\": \\"aeccd013-c99e-45cf-86ba-97ed8cd28075\\",\\n      \\"facets\\": {},\\n      \\"deleted\\": false\\n    },\\n  ]\\n} \\n```\\n\\n#### Alt: Specify a Dataset \\n\\nQueries about known datasets are also supported: `http://localhost:5000/api/v1/namespaces/{namespace}/datasets/{dataset}`.\\n\\nTo query the API concerning the `public.categories` dataset above, you would use: `curl http://localhost:5000/api/v1/namespaces/food_delivery/datasets/public.categories | jq`.\\n\\n#### Dataset Query Output \\n\\n```\\n{\\n  \\"id\\": {\\n    \\"namespace\\": \\"food_delivery\\",\\n    \\"name\\": \\"public.categories\\"\\n  },\\n  \\"type\\": \\"DB_TABLE\\",\\n  \\"name\\": \\"public.categories\\",\\n  \\"physicalName\\": \\"public.categories\\",\\n  \\"createdAt\\": \\"2022-07-12T16:22:12.792434Z\\",\\n  \\"updatedAt\\": \\"2022-07-12T16:24:33.355699Z\\",\\n  \\"namespace\\": \\"food_delivery\\",\\n  \\"sourceName\\": \\"analytics_db\\",\\n  \\"fields\\": [\\n    {\\n      \\"name\\": \\"id\\",\\n      \\"type\\": \\"INTEGER\\",\\n      \\"tags\\": [],\\n      \\"description\\": \\"The unique ID of the category.\\"\\n    },\\n    {\\n      \\"name\\": \\"name\\",\\n      \\"type\\": \\"VARCHAR\\",\\n      \\"tags\\": [],\\n      \\"description\\": \\"The name of the category.\\"\\n    },\\n    {\\n      \\"name\\": \\"menu_id\\",\\n      \\"type\\": \\"INTEGER\\",\\n      \\"tags\\": [],\\n      \\"description\\": \\"The ID of the menu related to the category.\\"\\n    },\\n    {\\n      \\"name\\": \\"description\\",\\n      \\"type\\": \\"TEXT\\",\\n      \\"tags\\": [],\\n      \\"description\\": \\"The description of the category.\\"\\n    }\\n  ],\\n  \\"tags\\": [],\\n  \\"lastModifiedAt\\": \\"2022-07-12T16:24:33.355699Z\\",\\n  \\"lastLifecycleState\\": null,\\n  \\"description\\": \\"A table for categories.\\",\\n  \\"currentVersion\\": \\"aeccd013-c99e-45cf-86ba-97ed8cd28075\\",\\n  \\"facets\\": {},\\n  \\"deleted\\": false\\n}\\n```\\n\\n#### View Key Data about Jobs \\n\\nThe query to see all the jobs in the `food_delivery` namespace has the following format: `http://localhost:5000/api/v1/namespaces/{namespace}/jobs`.\\n\\nTo view all the jobs in `food_delivery` you could use: `curl http://localhost:5000/api/v1/namespaces/food_delivery/jobs | jq`.\\n\\n#### Jobs Query Output \\n\\n```\\n{\\n  \\"totalCount\\": 15,\\n  \\"jobs\\": [\\n    {\\n      \\"id\\": {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"example.delivery_times_7_days\\"\\n      },\\n      \\"type\\": \\"BATCH\\",\\n      \\"name\\": \\"example.delivery_times_7_days\\",\\n      \\"createdAt\\": \\"2022-07-12T16:22:13.325864Z\\",\\n      \\"updatedAt\\": \\"2022-07-12T16:36:44.355699Z\\",\\n      \\"namespace\\": \\"food_delivery\\",\\n      \\"inputs\\": [\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.delivery_7_days\\"\\n        }\\n      ],\\n      \\"outputs\\": [],\\n      \\"location\\": \\"https://github.com/example/jobs/blob/2294bc15eb49071f38425dc927e48655530a2f2e/delivery_times_7_days.py\\",\\n      \\"context\\": {\\n        \\"sql\\": \\"INSERT INTO top_delivery_times (order_id, order_placed_on, order_dispatched_on, order_delivered_on, order_delivery_time,\\\\n    customer_email, restaurant_id, driver_id)\\\\n  SELECT order_id, order_placed_on, order_delivered_on, DATEDIFF(minute, order_placed_on, order_delivered_on) AS order_delivery_time,\\\\n    customer_email, restaurant_id, driver_id\\\\n    FROM delivery_7_days\\\\nGROUP BY restaurant_id\\\\nORDER BY order_delivery_time DESC\\\\n   LIMIT 1;\\"\\n      },\\n      \\"description\\": \\"Determine weekly top delivery times by restaurant.\\",\\n      \\"latestRun\\": {\\n        \\"id\\": \\"5d75efd9-4ec6-4fcc-931a-0c67faec9f92\\",\\n        \\"createdAt\\": \\"2022-07-12T16:22:23.676635Z\\",\\n        \\"updatedAt\\": \\"2022-07-12T16:36:44.355699Z\\",\\n        \\"nominalStartTime\\": \\"2022-07-12T16:34:00Z\\",\\n        \\"nominalEndTime\\": \\"2022-07-12T16:36:00Z\\",\\n        \\"state\\": \\"FAILED\\",\\n        \\"startedAt\\": \\"2022-07-12T16:34:13.355699Z\\",\\n        \\"endedAt\\": \\"2022-07-12T16:36:44.355699Z\\",\\n        \\"durationMs\\": 151000,\\n        \\"args\\": {},\\n        \\"jobVersion\\": {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"example.delivery_times_7_days\\",\\n          \\"version\\": \\"e9eafa5b-e334-358d-a3b4-61c8d3de75f3\\"\\n        },\\n        \\"inputVersions\\": [\\n          {\\n            \\"namespace\\": \\"food_delivery\\",\\n            \\"name\\": \\"public.delivery_7_days\\",\\n            \\"version\\": \\"581a0b65-c46a-3087-8d27-4c6e9899c64c\\"\\n          }\\n        ],\\n        \\"outputVersions\\": [],\\n        \\"context\\": {\\n          \\"sql\\": \\"INSERT INTO top_delivery_times (order_id, order_placed_on, order_dispatched_on, order_delivered_on, order_delivery_time,\\\\n    customer_email, restaurant_id, driver_id)\\\\n  SELECT order_id, order_placed_on, order_delivered_on, DATEDIFF(minute, order_placed_on, order_delivered_on) AS order_delivery_time,\\\\n    customer_email, restaurant_id, driver_id\\\\n    FROM delivery_7_days\\\\nGROUP BY restaurant_id\\\\nORDER BY order_delivery_time DESC\\\\n   LIMIT 1;\\"\\n        },\\n        \\"facets\\": {}\\n      },\\n      \\"facets\\": {},\\n      \\"currentVersion\\": \\"a4d1a0fc-1d6c-4904-a94c-7776f78f4435\\"\\n    }, \\n  ]\\n}\\n```\\nAs with datasets, you can query the API for a specific job by appending the job name to the query above.\\n\\n#### Get a Lineage Graph \\n\\nThe lineage graph is the basis of the UI\u2019s visualization of a pipeline. To view a lineage graph, query the API with either a dataset or job specified as the `nodeId`. \\n\\n##### Job Query \\n```\\nNODE=\u201djob:food_delivery:example.etl_delivery_7_days\u201d\\ncurl -s \\"http://localhost:5000/api/v1/lineage?nodeId=$NODE\\" | jq \u2013arg N \u201c${NODE}\u201d \u2018.graph[] | select(.id==$N)\u2019\\n```\\n\\n##### Job Query Output \\n```\\n{\\n  \\"id\\": \\"job:food_delivery:example.etl_delivery_7_days\\",\\n  \\"type\\": \\"JOB\\",\\n  \\"data\\": {\\n    \\"type\\": \\"BATCH\\",\\n    \\"id\\": {\\n      \\"namespace\\": \\"food_delivery\\",\\n      \\"name\\": \\"example.etl_delivery_7_days\\"\\n    },\\n    \\"name\\": \\"example.etl_delivery_7_days\\",\\n    \\"createdAt\\": \\"2022-07-13T13:38:40.059605Z\\",\\n    \\"updatedAt\\": \\"2022-07-13T13:49:45.103063Z\\",\\n    \\"namespace\\": \\"food_delivery\\",\\n    \\"inputs\\": [\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.restaurants\\"\\n      },\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.customers\\"\\n      },\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.drivers\\"\\n      },\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.order_status\\"\\n      },\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.orders_7_days\\"\\n      }\\n    ],\\n    \\"outputs\\": [\\n      {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"public.delivery_7_days\\"\\n      }\\n    ],\\n    \\"location\\": \\"https://github.com/example/jobs/blob/c87f2a40553cfa4ae7178083a068bf1d0c6ca3a8/etl_delivery_7_days.py\\",\\n    \\"context\\": {\\n      \\"sql\\": \\"INSERT INTO delivery (order_id, order_placed_on, order_dispatched_on, order_delivered_on, customer_email,\\\\n      customer_address, discount_id, menu_id, restaurant_id, restaurant_address, menu_item_id, category_id, driver_id)\\\\n  SELECT o.order_id, o.placed_on AS order_placed_on,\\\\n    (SELECT transitioned_at FROM order_status WHERE order_id == o.order_id AND status = \'DISPATCHED\') AS order_dispatched_on,\\\\n    (SELECT transitioned_at FROM order_status WHERE order_id == o.order_id AND status = \'DELIVERED\') AS order_delivered_on,\\\\n    c.email AS customer_email, c.address AS customer_address, o.discount_id, o.menu_id, o.restaurant_id,\\\\n      r.address, o.menu_item_id, o.category_id, d.id AS driver_id\\\\n    FROM orders_7_days AS o\\\\n   INNER JOIN order_status AS os\\\\n      ON os.order_id = o.order_id\\\\n   INNER JOIN customers AS c\\\\n      ON c.id = os.customer_id\\\\n   INNER JOIN restaurants AS r\\\\n      ON r.id = os.restaurant_id\\\\n   INNER JOIN drivers AS d\\\\n      ON d.id = os.driver_id\\\\n   WHERE os.transitioned_at >= NOW() - interval \'7 days\';\\"\\n    },\\n    \\"description\\": \\"Loads new deliveries for the week.\\",\\n    \\"latestRun\\": {\\n      \\"id\\": \\"ad65c352-ae92-41d3-9795-d31639f816d2\\",\\n      \\"createdAt\\": \\"2022-07-13T13:38:49.962723Z\\",\\n      \\"updatedAt\\": \\"2022-07-13T13:49:45.103063Z\\",\\n      \\"nominalStartTime\\": \\"2022-07-13T13:46:00Z\\",\\n      \\"nominalEndTime\\": \\"2022-07-13T13:49:00Z\\",\\n      \\"state\\": \\"COMPLETED\\",\\n      \\"startedAt\\": \\"2022-07-13T13:46:40.103063Z\\",\\n      \\"endedAt\\": \\"2022-07-13T13:49:45.103063Z\\",\\n      \\"durationMs\\": 185000,\\n      \\"args\\": {},\\n      \\"jobVersion\\": {\\n        \\"namespace\\": \\"food_delivery\\",\\n        \\"name\\": \\"example.etl_delivery_7_days\\",\\n        \\"version\\": \\"c222a72e-92cc-3bb6-b3b7-c174cbc76387\\"\\n      },\\n      \\"inputVersions\\": [\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.order_status\\",\\n          \\"version\\": \\"ee4d0794-c7e8-3bdd-94f5-83a43f1eb6f6\\"\\n        },\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.restaurants\\",\\n          \\"version\\": \\"7f5d9f89-202a-305d-a338-2423269af7bf\\"\\n        },\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.orders_7_days\\",\\n          \\"version\\": \\"777358f4-1669-33fa-88f4-780d00d34f15\\"\\n        },\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.drivers\\",\\n          \\"version\\": \\"32343496-969e-3f66-9ad7-13cabf16ca26\\"\\n        },\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.customers\\",\\n          \\"version\\": \\"db58139b-6eec-3efb-b589-d3cad7138ae4\\"\\n        }\\n      ],\\n      \\"outputVersions\\": [\\n        {\\n          \\"namespace\\": \\"food_delivery\\",\\n          \\"name\\": \\"public.delivery_7_days\\",\\n          \\"version\\": \\"047484a8-33f6-3b1f-bd78-584e8705a756\\"\\n        }\\n      ],\\n      \\"context\\": {\\n        \\"sql\\": \\"INSERT INTO delivery (order_id, order_placed_on, order_dispatched_on, order_delivered_on, customer_email,\\\\n      customer_address, discount_id, menu_id, restaurant_id, restaurant_address, menu_item_id, category_id, driver_id)\\\\n  SELECT o.order_id, o.placed_on AS order_placed_on,\\\\n    (SELECT transitioned_at FROM order_status WHERE order_id == o.order_id AND status = \'DISPATCHED\') AS order_dispatched_on,\\\\n    (SELECT transitioned_at FROM order_status WHERE order_id == o.order_id AND status = \'DELIVERED\') AS order_delivered_on,\\\\n    c.email AS customer_email, c.address AS customer_address, o.discount_id, o.menu_id, o.restaurant_id,\\\\n      r.address, o.menu_item_id, o.category_id, d.id AS driver_id\\\\n    FROM orders_7_days AS o\\\\n   INNER JOIN order_status AS os\\\\n      ON os.order_id = o.order_id\\\\n   INNER JOIN customers AS c\\\\n      ON c.id = os.customer_id\\\\n   INNER JOIN restaurants AS r\\\\n      ON r.id = os.restaurant_id\\\\n   INNER JOIN drivers AS d\\\\n      ON d.id = os.driver_id\\\\n   WHERE os.transitioned_at >= NOW() - interval \'7 days\';\\"\\n      },\\n      \\"facets\\": {}\\n    }\\n  },\\n  \\"inEdges\\": [\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.customers\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.drivers\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.order_status\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.orders_7_days\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.restaurants\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    }\\n  ],\\n  \\"outEdges\\": [\\n    {\\n      \\"origin\\": \\"job:food_delivery:example.etl_delivery_7_days\\",\\n      \\"destination\\": \\"dataset:food_delivery:public.delivery_7_days\\"\\n    }\\n  ]\\n}\\n```\\n\\n##### Dataset Query\\n```\\nNODE=\u201ddataset:food_delivery:public.customers\u201d\\ncurl -s \\"http://localhost:5000/api/v1/lineage?nodeId=$NODE\\" | jq \u2013arg N \u201c${NODE}\u201d \u2018.graph[] | select(.id==$N)\u2019\\n```\\n\\n##### Dataset Query Output\\n```\\n{\\n  \\"id\\": \\"dataset:food_delivery:public.customers\\",\\n  \\"type\\": \\"DATASET\\",\\n  \\"data\\": {\\n    \\"type\\": \\"DB_TABLE\\",\\n    \\"id\\": {\\n      \\"namespace\\": \\"food_delivery\\",\\n      \\"name\\": \\"public.customers\\"\\n    },\\n    \\"name\\": \\"public.customers\\",\\n    \\"physicalName\\": \\"public.customers\\",\\n    \\"createdAt\\": \\"2022-07-13T13:38:39.681949Z\\",\\n    \\"updatedAt\\": \\"2022-07-13T13:46:09.103063Z\\",\\n    \\"namespace\\": \\"food_delivery\\",\\n    \\"sourceName\\": \\"analytics_db\\",\\n    \\"fields\\": [\\n      {\\n        \\"name\\": \\"id\\",\\n        \\"type\\": \\"INTEGER\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"The unique ID of the customer.\\"\\n      },\\n      {\\n        \\"name\\": \\"created_at\\",\\n        \\"type\\": \\"TIMESTAMP\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"An ISO-8601 timestamp representing the date/time the customer was created.\\"\\n      },\\n      {\\n        \\"name\\": \\"updated_at\\",\\n        \\"type\\": \\"TIMESTAMP\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"An ISO-8601 timestamp representing the date/time the customer was updated.\\"\\n      },\\n      {\\n        \\"name\\": \\"name\\",\\n        \\"type\\": \\"VARCHAR\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"The name of the customer.\\"\\n      },\\n      {\\n        \\"name\\": \\"email\\",\\n        \\"type\\": \\"VARCHAR\\",\\n        \\"tags\\": [\\n          \\"PII\\"\\n        ],\\n        \\"description\\": \\"The email address of the customer.\\"\\n      },\\n      {\\n        \\"name\\": \\"address\\",\\n        \\"type\\": \\"VARCHAR\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"The address of the customer.\\"\\n      },\\n      {\\n        \\"name\\": \\"phone\\",\\n        \\"type\\": \\"VARCHAR\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"The phone number of the customer.\\"\\n      },\\n      {\\n        \\"name\\": \\"city_id\\",\\n        \\"type\\": \\"INTEGER\\",\\n        \\"tags\\": [],\\n        \\"description\\": \\"The ID of the city related to the customer.\\"\\n      }\\n    ],\\n    \\"tags\\": [],\\n    \\"lastModifiedAt\\": \\"2022-07-13T13:46:09.103063Z\\",\\n    \\"description\\": \\"A table for customers.\\",\\n    \\"lastlifecycleState\\": null\\n  },\\n  \\"inEdges\\": [\\n    {\\n      \\"origin\\": \\"job:food_delivery:example.etl_customers\\",\\n      \\"destination\\": \\"dataset:food_delivery:public.customers\\"\\n    }\\n  ],\\n  \\"outEdges\\": [\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.customers\\",\\n      \\"destination\\": \\"job:food_delivery:example.email_discounts\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.customers\\",\\n      \\"destination\\": \\"job:food_delivery:example.etl_delivery_7_days\\"\\n    },\\n    {\\n      \\"origin\\": \\"dataset:food_delivery:public.customers\\",\\n      \\"destination\\": \\"job:food_delivery:example.orders_popular_day_of_week\\"\\n    }\\n  ]\\n}\\n```\\n\\n## Additional Resources\\n\\nFor a list of all the available queries and more information about the API, see the Marquez API Reference: https://marquezproject.github.io/marquez/openapi.html.\\n\\nInterested in contributing to the project? Read our guide for new contributors: https://github.com/MarquezProject/marquez/blob/main/CONTRIBUTING.md.\\n\\nJoin us on Slack: http://bit.ly/MarquezSlack."}]}')}}]);